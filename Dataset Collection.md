# Dataset Collection

1. 视频资源

   - 从包含双人交谈的视频播客，影视节目中采集

   - 分辨率超过 1080p

   - 利用FaceXFormer [41]自动过滤掉22岁以下个人的面部视频。

   - 使用 OpenCV 来确保面部区域至少为 256 × 256 像素

2. 手动注释筛查（不适用）
3. 字幕检测
   - 过滤掉包含噪音的视频
   - OCR字幕检测
4. CodeFormer提高过滤后模糊视频质量
5. **多人脸处理**
   1. 视频分割处理
   2. 说话人人脸识别跟踪+说话人语音识别+说话人字幕跟踪
6. 表情提取
   - DWPose提取面部关键点
7. 视频描述
   - 使用PLLaVA生成初始注释
   - 利用了类似于LLM交互中使用的基于提示的技术来提高有效性。
   - 字幕模型的任务是生成视频中角色的**单句描述**，详细说明他们的种族、性别、年龄、外貌属性（例如发型和头发颜色）、情感、动作（主要是说话）、背景环境和照明条件。
   - 为了捕捉视频中角色的动态动作（即头部运动），我们在生成字幕的同时随机采样了 3 个非连续帧，以平衡文本准确性和处理效率
   - 最后，我们手动仔细检查所有注释，以确保一致性、标准化和高质量
8. 音频过滤
   - 应用了额外的音频过滤来支持音频驱动的说话头生成。确保视频音频和嘴唇运动之间的准确对齐至关重要。值得注意的是，在LRW [4]上预训练的SyncNet [5]在非英语语音方面显示出显著的评分偏差。因此，我们采用了[33]来重新训练一个新的SyncNet，然后我们用它为每个视频生成SyncNet分数。过滤掉唇音频同步性差的样本，以确保整体数据集的完整性。

